{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import spearmanr\n",
    "import matplotlib as mpl\n",
    "import re\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import os\n",
    "\n",
    "# Set global font sizes - for manuscript\n",
    "mpl.rcParams['font.size'] = 20\n",
    "mpl.rcParams['axes.labelsize'] = 28\n",
    "mpl.rcParams['xtick.labelsize'] = 24\n",
    "mpl.rcParams['ytick.labelsize'] = 24\n",
    "mpl.rcParams['legend.fontsize'] = 18\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def spearman_correlation_by_classification(data: pd.DataFrame, metric1: str, metric2: str):\n",
    "    \"\"\"\n",
    "    Compute the Spearman rank correlation coefficient and p-value for two subsets of data defined by classification.\n",
    "    \n",
    "    The data is split into two groups:\n",
    "      - Group \"B\": where Classification is exactly \"B\".\n",
    "      - Group \"LSW/HSW\": where Classification is either \"LSW\" or \"HSW\".\n",
    "    \n",
    "    Parameters:\n",
    "        data (pd.DataFrame): The DataFrame containing your dataset.\n",
    "        metric1 (str): The name of the first metric (column) in the DataFrame.\n",
    "        metric2 (str): The name of the second metric (column) in the DataFrame.\n",
    "        \n",
    "    Returns:\n",
    "        dict: A dictionary with keys \"B\" and \"LSW/HSW\". Each key maps to a tuple (rho, p_value)\n",
    "              where rho is the Spearman correlation coefficient and p_value is the corresponding p-value.\n",
    "    \"\"\"\n",
    "    # Check if required columns are present\n",
    "    required_cols = {metric1, metric2, \"Classification\"}\n",
    "    missing = required_cols - set(data.columns)\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing required columns in DataFrame: {missing}\")\n",
    "\n",
    "    # Split data into two subsets:\n",
    "    # Subset for Classification \"B\"\n",
    "    subset_B = data[data[\"Classification\"] == \"B\"]\n",
    "    # Subset for Classification either \"LSW\" or \"HSW\"\n",
    "    subset_LSW_HSW = data[data[\"Classification\"].isin([\"LSW\", \"HSW\"])]\n",
    "\n",
    "    # Function to compute Spearman correlation, dropping missing values\n",
    "    def compute_corr(df_subset: pd.DataFrame):\n",
    "        df_clean = df_subset[[metric1, metric2]].dropna()\n",
    "        return spearmanr(df_clean[metric1], df_clean[metric2])\n",
    "    \n",
    "    # Calculate the correlations for each group\n",
    "    results = {}\n",
    "    results[\"B\"] = compute_corr(subset_B)\n",
    "    results[\"LSW/HSW\"] = compute_corr(subset_LSW_HSW)\n",
    "    \n",
    "    return results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "    # Replace the file path with your actual CSV file location.\n",
    "    file_path = r\"C:\\Users\\Feifei\\Box\\BR_remote_sensing\\ebi_combined_statistics.csv\"\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading CSV file: {e}\")\n",
    "        exit(1)\n",
    "    \n",
    "    # Define the two metrics you want to compare (update with actual column names from your CSV).\n",
    "    metric_a = \"Iw\"  # Replace with your actual column name for metric 1\n",
    "    metric_b = \"norm_migration_rate\"  # Replace with your actual column name for metric 2\n",
    "    \n",
    "    try:\n",
    "        results = spearman_correlation_by_classification(df, metric_a, metric_b)\n",
    "        for group, (rho, p_value) in results.items():\n",
    "            print(f\"Group '{group}': Spearman rho = {rho}, p-value = {p_value}\")\n",
    "    except ValueError as ve:\n",
    "        print(ve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "def count_folders_with_reprojected_gpkg(base_path):\n",
    "    \"\"\"\n",
    "    Count the number of sub-folders in base_path that contain at least one GeoPackage (.gpkg) file \n",
    "    ending with '_reprojected.gpkg'.\n",
    "    \n",
    "    Parameters:\n",
    "        base_path (str): The path to the directory containing the river folders.\n",
    "    \n",
    "    Returns:\n",
    "        int: Number of folders that have the _reprojected.gpkg file.\n",
    "    \"\"\"\n",
    "    count = 0\n",
    "    # List all items in the base_path and filter for directories\n",
    "    for folder in os.listdir(base_path):\n",
    "        folder_path = os.path.join(base_path, folder)\n",
    "        if os.path.isdir(folder_path):\n",
    "            # Use glob to search for any file ending with _reprojected.gpkg in the current folder\n",
    "            matching_files = glob.glob(os.path.join(folder_path, \"*_reprojected.gpkg\"))\n",
    "            if matching_files:\n",
    "                count += 1\n",
    "    return count\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Update the path as needed for your environment\n",
    "    ebi_results_path = r\"C:\\Users\\Feifei\\Box\\BR_remote_sensing\\ebi_results\"\n",
    "    \n",
    "    num_folders = count_folders_with_reprojected_gpkg(ebi_results_path)\n",
    "    print(f\"Number of folders having a '_reprojected.gpkg' file: {num_folders}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score  # ← import metrics\n",
    "\n",
    "# 1) Load the dataset\n",
    "csv_path = r\"C:\\Users\\Feifei\\Box\\BR_remote_sensing\\ebi_combined_statistics.csv\"\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# 2) Rename slope column for convenience\n",
    "df.rename(columns={'Slope (cm/km) ': 'Slope_cm_per_km'}, inplace=True)\n",
    "\n",
    "# 3) Map feature names and targets to LaTeX axis labels\n",
    "label_map = {\n",
    "    'dim_Q':                 r'$\\mathit{Q}^*$',\n",
    "    'cov_discharge_site':    r'$Q_{CV}$',\n",
    "    'Slope_cm_per_km':       r'$\\mathit{S}$',\n",
    "    'mean_ebi_site':         r'$\\langle\\overline{\\mathit{eBI}}\\rangle$',\n",
    "    'std_ebi_site':          r'$\\langle\\overline{\\mathit{eBI_{std}}}\\rangle$',\n",
    "    'T_R':                   r'$T_{R}$',\n",
    "    'CB/Aw':                 r'$CB_{norm}$',\n",
    "    'eBI_BI_ratio_site':     r'$\\langle\\overline{\\mathit{eBI}}\\rangle/\\langle\\overline{\\mathit{BI}}\\rangle$',\n",
    "    'Iw':                    r'$I_{w}$'\n",
    "}\n",
    "\n",
    "# 4) Define which features to use for each target variable\n",
    "features_map = {\n",
    "    'mean_ebi_site':       ['dim_Q', 'cov_discharge_site', 'Slope_cm_per_km'],\n",
    "    'T_R':                 ['dim_Q', 'cov_discharge_site', 'mean_ebi_site', 'std_ebi_site'],\n",
    "    'CB/Aw':               ['dim_Q', 'cov_discharge_site', 'T_R', 'mean_ebi_site', 'std_ebi_site'],\n",
    "    # for eBI_BI_ratio_site use: dim_Q, Slope_cm_per_km, Iw, cov_discharge_site\n",
    "    'eBI_BI_ratio_site':   ['dim_Q', 'Slope_cm_per_km', 'Iw', 'cov_discharge_site']\n",
    "}\n",
    "\n",
    "def fit_and_plot_rf(data, river_type, target, features):\n",
    "    # a) Prepare X, y\n",
    "    X = data[features]\n",
    "    y = data[target]\n",
    "    \n",
    "    # b) Train/test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.3, random_state=42\n",
    "    )\n",
    "    \n",
    "    # c) Fit random forest\n",
    "    rf = RandomForestRegressor(n_estimators=500, random_state=42)\n",
    "    rf.fit(X_train, y_train)\n",
    "    \n",
    "    # d) Compute predictions and metrics\n",
    "    y_pred = rf.predict(X_test)\n",
    "    rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "    r2   = r2_score(y_test, y_pred)\n",
    "    \n",
    "    # print to console\n",
    "    print(f\"{river_type} {target} — RMSE: {rmse:.3f}, R²: {r2:.3f}\")\n",
    "    \n",
    "    # e) Extract and sort importances\n",
    "    imps = rf.feature_importances_\n",
    "    order = imps.argsort()\n",
    "    y_labels = [label_map[f] for f in [features[i] for i in order]]\n",
    "    \n",
    "    # f) Plot feature importances\n",
    "    fig, ax = plt.subplots(figsize=(7, 6))\n",
    "    ax.barh(y_labels, imps[order], align='center')\n",
    "    ax.set_xlabel(\"Feature Importance\")\n",
    "    ax.set_title(f\"{river_type}\\n{label_map[target]}\", fontsize=14)\n",
    "    \n",
    "    # annotate metrics inside the plot\n",
    "    ax.text(\n",
    "        0.95, 0.05,\n",
    "        f\"RMSE: {rmse:.2f}\\n$R^2$: {r2:.2f}\",\n",
    "        transform=ax.transAxes,\n",
    "        ha=\"right\", va=\"bottom\",\n",
    "        bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"white\", alpha=0.7)\n",
    "    )\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # g) Sanitize filename and choose suffix\n",
    "    safe_target = re.sub(r'[<>:\"/\\\\|?*]', '_', target)\n",
    "    suffix = '_B' if river_type == 'Braided' else '_W'\n",
    "    outdir = r\"C:\\Users\\Feifei\\Box\\BR_remote_sensing\\figures\"\n",
    "    os.makedirs(outdir, exist_ok=True)\n",
    "    filename = os.path.join(outdir, f\"11_{safe_target}{suffix}.pdf\")\n",
    "    \n",
    "    # h) Save to PDF\n",
    "    fig.savefig(\n",
    "        filename,\n",
    "        format='pdf',\n",
    "        dpi=500,\n",
    "        bbox_inches='tight',\n",
    "        transparent=True\n",
    "    )\n",
    "    plt.show()\n",
    "\n",
    "# 5) Split into braided vs wandering\n",
    "df_braided   = df[df['Classification'] == 'B']\n",
    "df_wandering = df[df['Classification'].isin(['LSW','HSW'])]\n",
    "\n",
    "# 6) Loop through each target and save both _B and _W versions\n",
    "for target, feats in features_map.items():\n",
    "    fit_and_plot_rf(df_braided,   \"Braided\",  target, feats)\n",
    "    fit_and_plot_rf(df_wandering, \"Wandering\", target, feats)\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
